# To run this file, I installed the following packages: pandas, openpyxl

import argparse
import pandas as pd
import pymongo
from datetime import datetime

# Establish DB connection
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["Project2"]
# Individual QA reports (4)
collection1 = mydb["Collection1"]
# Class QA report data dump
collection2 = mydb["Collection2"]


# Method to insert Excel files inot MongoDB
def insert_into_mongodb(collection, data):
    collection.insert_many(data)

# Method to execute specific queries
def get_data(collection, query):
    documents = collection.find(query)
    return pd.DataFrame(list(documents))

# Argparse scripting
parser = argparse.ArgumentParser(description="Input, manage and export Excel files in the MongoDB")

# Scripts to insert Excel files into collections
parser.add_argument("--file", help="Excel file to read")
parser.add_argument("--insert_collection1", action="store_true", help="Insert data into Collection 1")
parser.add_argument("--insert_collection2", action="store_true", help="Insert data into Collection 2")
# Scripts for specific database calls
parser.add_argument("--user_yana", action="store_true", help="Find bugs reported by me")
parser.add_argument("--find_repeatables", action="store_true", help="Find repeatable bugs")
parser.add_argument("--find_blockers", action="store_true", help="Find blocker bugs")
parser.add_argument("--find_date", action="store_true", help="Find bugs for a specific date")
parser.add_argument("--specific_location", action="store_true", help="Find first, middle and last bugs")
parser.add_argument("--user_kevin_chaja", action="store_true", help="Find bugs reported by professor")
# Generate CSV reports to view database calls
parser.add_argument("--create_report", help="Output CSV file name", default="report.csv")

args = parser.parse_args()

# Use python main.py --insert_collection1 --file Report1.xlsx to run in console
if args.insert_collection1:
    collection = mydb["Collection1"]
    df = pd.read_excel(args.file)
    data = df.to_dict(orient="records")
    insert_into_mongodb(collection, data)
    print(f"Successfully inserted data from '{args.file}' into Collection 1")

# Use python main.py --insert_collection2 --file DBDump.xlsx to run in console
if args.insert_collection2:
    collection = mydb["Collection2"]
    df = pd.read_excel(args.file)
    # Data cleaning, drops any rows with incomplete and duplicate information
    # As well as that one line that contains sample information
    clean_data = df.dropna()
    clean_data = clean_data.drop_duplicates()
    clean_data = clean_data[clean_data.iloc[:, 8] != "Your name ex: Kevin Chaja"]
    data = clean_data.to_dict(orient="records")
    insert_into_mongodb(collection, data)
    print(f"Successfully inserted data from '{args.file}' into Collection 2")

# Use python main.py --user_yana --create_report yana_report.csv to run in console
if args.user_yana:
    print("Looking for test cases generated by Yana...")
    query = {"Test Owner": "Yana Zaynullina"}
    df1 = get_data(collection1, query)
    df2 = get_data(collection2, query)
    combined_df = pd.concat([df1, df2]).reset_index(drop=True)
    combined_df = combined_df.drop(columns=['_id'], errors='ignore')
    # Removing trailing white spaces to avoid duplicates
    for col in combined_df.select_dtypes(include=["object"]).columns:
        combined_df[col] = combined_df[col].str.strip()
    combined_df = combined_df.drop_duplicates().dropna()
    # Export to CSV
    combined_df.to_csv(args.create_report, index=False)
    print(f"Generated a new report: '{args.create_report}'")

# Use python main.py --find_repeatables --create_report repeatables_report.csv to run in console
if args.find_repeatables:
    print("Looking for repeatable bugs...")
    query = {"Repeatable?": {"$regex": "^(?!Yes/no$|yes/no$)(?i:yes|y)"}}
    df1 = get_data(collection1, query)
    df2 = get_data(collection2, query)
    combined_df = pd.concat([df1, df2]).reset_index(drop=True)
    combined_df = combined_df.drop(columns=['_id'], errors='ignore')
    combined_df = combined_df.drop_duplicates().dropna()
    # Export to CSV
    combined_df.to_csv(args.create_report, index=False)
    print(f"Generated a new report: '{args.create_report}'")

# Use python main.py --find_blockers --create_report blockers_report.csv to run in console
if args.find_blockers:
    print("Looking for blocker bugs...")
    query = {"Blocker?": {"$regex": "^(?!Yes/no$|yes/no$)(?i:yes|y)"}}
    df1 = get_data(collection1, query)
    df2 = get_data(collection2, query)
    combined_df = pd.concat([df1, df2]).reset_index(drop=True)
    combined_df = combined_df.drop(columns=['_id'], errors='ignore')
    combined_df = combined_df.drop_duplicates().dropna()
    combined_df.to_csv(args.create_report, index=False)
    print(f"Generated a new report: '{args.create_report}'")

# Use python main.py --find_date --create_report date_report.csv to run in console
if args.find_date:
    print("Looking for bugs reported on March 19th, 2024...")
    target_date = datetime(2024, 3, 19)
    query = {"Build #": target_date}
    df1 = get_data(collection1, query)
    df2 = get_data(collection2, query)
    combined_df = pd.concat([df1, df2]).reset_index(drop=True)
    combined_df = combined_df.drop(columns=['_id'], errors='ignore')
    combined_df = combined_df.drop_duplicates().dropna()
    combined_df.to_csv(args.create_report, index=False)
    print(f"Generated a new report: '{args.create_report}'")

# Use python main.py --user_kevin_chaja --create_report kevin_chaja_report.csv to run in console
if args.user_kevin_chaja:
    print("Looking for bugs reported by Kevin Chaja...")
    query = {"Test Owner": "Kevin Chaja"}
    df = get_data(collection2, query)
    df = df.drop_duplicates().dropna()
    df = df.drop(columns=['_id'], errors='ignore')
    # Export to CSV
    df.to_csv(args.create_report, index=False)
    print(f"Generated a new report: '{args.create_report}'")

# Use python main.py --specific_location --create_report location_report.csv to run in console
if args.specific_location:
    print("Looking for first, middle and last bugs...")
    query = {}
    df = get_data(collection2, query)
    total_rows = len(df)
    first_row = df.iloc[0:1]
    middle_row_index = total_rows//2
    middle_row = df.iloc[middle_row_index:middle_row_index+1]
    last_row = df.iloc[total_rows-1:total_rows]
    combined_df = pd.concat([first_row, middle_row, last_row])
    combined_df = combined_df.drop(columns=['_id'], errors='ignore')
    combined_df.to_csv(args.create_report, index=False)
    print(f"Generated a new report: '{args.create_report}'")

# Closing the connection
myclient.close()